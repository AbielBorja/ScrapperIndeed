{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read subsector occupations CSV\n",
    "\n",
    "# For each occupation, read each jobposts job_description, extract competences, add column and save file with ...competences_llm.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import openai\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.globals import set_debug\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPEN AI KEY\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-rBVJlXCeswQsTIRXgosYT3BlbkFJRupEcTiKXToudT9qUFwU\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY: str = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying with: ./infocomm/7-junio-sfco-raw/IT%20security%20operations.csv\n",
      "Working\n",
      "Truncating jobpost\n",
      "Trying with: ./infocomm/7-junio-sfco-raw/Information%20Security%20Analysts.csv\n",
      "Working\n",
      "Trying with: ./infocomm/7-junio-sfco-raw/Product%20Security%20and%20IT%20Security%20Integration%20Specialist.csv\n",
      "The CSV file is empty.\n",
      "Trying with: ./infocomm/7-junio-sfco-raw/Product%20risk%20specialist.csv\n",
      "Working\n",
      "Trying with: ./infocomm/7-junio-sfco-raw/Security%20architect.csv\n",
      "Working\n",
      "Trying with: ./infocomm/7-junio-sfco-raw/Database%20support%20engineer.csv\n",
      "Working\n",
      "Trying with: ./infocomm/7-junio-sfco-raw/Data%20center%20operations%20engineer.csv\n",
      "Working\n",
      "Trying with: ./infocomm/7-junio-sfco-raw/Support%20systems%20engineer.csv\n",
      "Working\n",
      "Trying with: ./infocomm/7-junio-sfco-raw/Computer%20Network%20Support%20Specialists.csv\n",
      "Working\n"
     ]
    }
   ],
   "source": [
    "occ_csv = \"./infocomm/infocomm_occupations.csv\"\n",
    "batch_date = \"7-junio-sfco\"\n",
    "\n",
    "\n",
    "occs_df = pd.read_csv(occ_csv)\n",
    "\n",
    "for occ in occs_df[\"OccupationQS\"]:\n",
    "    csv_file_string = f\"./infocomm/{batch_date}-raw/{occ}.csv\"\n",
    "\n",
    "    fileEmpty = False\n",
    "\n",
    "    print(f\"Trying with: {csv_file_string}\")\n",
    "\n",
    "    occ_df = pd.DataFrame()\n",
    "\n",
    "    try:\n",
    "        # Read the CSV file into a DataFrame\n",
    "        occ_df = pd.read_csv(csv_file_string)\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(\"The CSV file is empty.\")\n",
    "        fileEmpty = True\n",
    "        pass\n",
    "    except FileNotFoundError:\n",
    "        print(\"File not found.\")\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "    \n",
    "    if fileEmpty:\n",
    "        pass\n",
    "    else:\n",
    "        print(\"Working\")\n",
    "        competences = []\n",
    "\n",
    "        llm = OpenAI(model_name=\"gpt-3.5-turbo-instruct\", temperature = 0)\n",
    "\n",
    "        set_debug(False)\n",
    "\n",
    "        template = \"\"\" From the given document: {document}\n",
    "        Question: {question}\"\"\"\n",
    "        prompt = PromptTemplate(template=template, input_variables=[\"question\", \"document\"])\n",
    "        llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "        for x in occ_df[\"job_description\"]:\n",
    "            if len(str(x)) > 3:\n",
    "                #question = \"List all the competences, skills, abilities and knowledge found in the text.\"\n",
    "                question = \"Provide a concise list of competences, skills, abilities, and knowledge mentioned in the text. Split lengthy items into smaller components. Your response should solely consist of a list of competences. If an item contains commas, break it down into separate entities.\"\n",
    "                #clean x\n",
    "                clean_x = x.strip()\n",
    "\n",
    "                # Check that the 'clean_x' string is no longer than 4096 tokens as that's the limit for gpt-turbo-3.5 context\n",
    "                # If it's longer, truncate it to 4096 tokens.\n",
    "\n",
    "                # Initialize the tokenizer\n",
    "                tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "                # Tokenize the input string\n",
    "                tokens = tokenizer.encode(clean_x)\n",
    "                \n",
    "                # Check if the number of tokens exceeds 4096, I use 3700 because we also need to allocate the question in the prompt.\n",
    "                if len(tokens) > 3700:\n",
    "                    print(f\"Truncating jobpost\")\n",
    "                    truncated_tokens = tokens[:3700]\n",
    "                    # Decode the tokens back to a string\n",
    "                    clean_x = tokenizer.decode(truncated_tokens)\n",
    "\n",
    "                output_competences = llm_chain.run(question = question, document = clean_x)\n",
    "                competences.append(output_competences)    \n",
    "            else:\n",
    "                print(\"Job description not found\")\n",
    "                competences.append(\"Job description not found\")\n",
    "        \n",
    "        occ_df['competences_llm'] = competences\n",
    "        occ_df.to_csv(f\"./infocomm/{batch_date}-processed/{occ}_competences_llm.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
