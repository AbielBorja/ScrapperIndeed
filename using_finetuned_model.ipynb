{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPEN AI KEY\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-rBVJlXCeswQsTIRXgosYT3BlbkFJRupEcTiKXToudT9qUFwU\"\n",
    "\n",
    "OPENAI_API_KEY: str = os.environ.get(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "occupations_list = [\n",
    "    'ICT%20sales%20professional',\n",
    "    'Marketing%20manager',\n",
    "    'Product%20analyst',\n",
    "    'Product%20manager',\n",
    "    'Product%20designer',\n",
    "    'Business%20Intelligence%20professional',\n",
    "    'Infraestructure%20engineer',\n",
    "    'Infraestructure%20engineer',\n",
    "    'Infrastructure%20engineer',\n",
    "    'Computer%20Systems%20Analyst',\n",
    "    'Software%20infrastructure%20architect',\n",
    "    'Web%20developer',\n",
    "    'Software%20developer',\n",
    "    'App%20developer',\n",
    "    'User%20interface%20designer',\n",
    "    'Software%20engineer',\n",
    "    'Software%20architect',\n",
    "    'Software%20Quality%20Assurance%20Analysts%20and%20Testers',\n",
    "    'Embedded%20systems%20engineer',\n",
    "    'Web%20and%20Digital%20Interface%20Designers',\n",
    "    'Database%20infrastructure%20engineer',\n",
    "    'Network%20architect',\n",
    "    'Database%20Administrators',\n",
    "    'Database%20Architects',\n",
    "    'Network%20and%20Computer%20Systems%20Administrator',\n",
    "    'Artificial%20intelligence%20engineer',\n",
    "    'Machine%20Learning%20engineer',\n",
    "    'Data%20science%20engineer',\n",
    "    'Data%20analyst',\n",
    "    'Data%20scientist',\n",
    "    'Artificial%20Intelligence%20scientist',\n",
    "    'Data%20architect',\n",
    "    'ICT%20security%20specialist',\n",
    "    'IT%20security%20operations',\n",
    "    'Information%20Security%20Analysts',\n",
    "    'Product%20Security%20and%20IT%20Security%20Integration%20Specialist',\n",
    "    'Product%20risk%20specialist',\n",
    "    'Security%20architect',\n",
    "    'Database%20support%20engineer',\n",
    "    'Data%20center%20operations%20engineer',\n",
    "    'Support%20systems%20engineer',\n",
    "    'Computer%20Network%20Support%20Specialists'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.- ICT%20sales%20professional - 0\n",
      "2.- Analyzing occupation: Marketing%20manager\n",
      "3.- Analyzing occupation: Product%20analyst\n",
      "4.- Analyzing occupation: Product%20manager\n",
      "5.- Analyzing occupation: Product%20designer\n",
      "6.- Analyzing occupation: Business%20Intelligence%20professional\n",
      "7.- Analyzing occupation: Infraestructure%20engineer\n",
      "8.- Infrastructure%20engineer - 0\n",
      "9.- Analyzing occupation: Computer%20Systems%20Analyst\n",
      "10.- Analyzing occupation: Software%20infrastructure%20architect\n",
      "11.- Analyzing occupation: Web%20developer\n",
      "12.- Analyzing occupation: Software%20developer\n",
      "13.- Analyzing occupation: App%20developer\n",
      "14.- Analyzing occupation: User%20interface%20designer\n",
      "15.- Analyzing occupation: Software%20engineer\n"
     ]
    }
   ],
   "source": [
    "# Read dict KSA's\n",
    "\n",
    "dict_file = \"Golden/dict_ksao_v12-junio-2024.csv\"\n",
    "golden = pd.read_csv(dict_file)\n",
    "listText = list(golden[\"Text\"])\n",
    "setText  = set(listText)\n",
    "\n",
    "relations_df = pd.DataFrame()\n",
    "relations_df['source'] = None\n",
    "relations_df['target'] = None\n",
    "relations_df['ksao'] = None\n",
    "relations_df['value'] = None\n",
    "relations_df['origin'] = None\n",
    "\n",
    "relations_set = set()\n",
    "occ_count = 1\n",
    "\n",
    "for occ in occupations_list:\n",
    "    file_path = f'../GoogleForJobs/infocomm/7-junio-sfco-processed/{occ}_competences_llm.csv'\n",
    "    if os.path.isfile(file_path) and os.path.getsize(file_path) > 1:\n",
    "        print(f\"{occ_count}.- Analyzing occupation: {occ}\")\n",
    "        # Read the CSV file into a DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        for x in df[\"competences_llm\"]:\n",
    "            for item in x.split(\"\\n\"):\n",
    "                # TODO: Checar los casos en que en las competencias no están en lista numérica con punto '.', por ej:\n",
    "                # \n",
    "                # 1. Troubleshooting skills\n",
    "                # 2. Computer security knowledge\n",
    "                # 3. High-level experience in:\n",
    "                #     a. Very high performance/traffic web architectures\n",
    "                #     b. Configuration management\n",
    "                #     c. Large scale deployment methods\n",
    "                #     d. Ansible\n",
    "                # \n",
    "                # \n",
    "                #   o también:\n",
    "                # \n",
    "                # - Administration\n",
    "                # - Maintenance\n",
    "                # - Technical support\n",
    "                # - Local area network (LAN)\n",
    "                # - Connectivity\n",
    "                # - Departmental host system\n",
    "                # - Network operating s\n",
    "                # \n",
    "                # \n",
    "                # \n",
    "                #   o también:\n",
    "                # \n",
    "                # \n",
    "                # 4. Cyber Security Software tool proficiency\n",
    "                #     a. Darktrace\n",
    "                #     b. EDR\n",
    "                #     c. Security Operations Center (SOC)\n",
    "                #     d. SEIM\n",
    "                # \n",
    "                # \n",
    "                # \n",
    "                # \n",
    "                # \n",
    "                # Checar: if \". \" in item or \"- \" in item:\n",
    "                if \". \" in item:\n",
    "                    ksa = item.split(\". \")[1]\n",
    "                    found = False\n",
    "                    \n",
    "                    #Busca en \"Standard text\"\n",
    "                    # for golden_ksa in golden[\"Standard text\"]:\n",
    "                    #     if golden_ksa == ksa:\n",
    "                    #         index = golden.index[golden[\"Standard text\"] == golden_ksa].tolist()[0]\n",
    "                    #         _ksa = golden.at[index, 'Label']\n",
    "                    #         record = {'source': occ, 'target': ksa, 'ksao': _ksa,'value': 1, 'origin': 'Standard text'}\n",
    "                    #         relations_set.add(tuple(record.items()))\n",
    "                    #         relations_df = pd.concat([relations_df, pd.DataFrame([record])], ignore_index=True)\n",
    "                    #         found = True\n",
    "                    #         break\n",
    "                    \n",
    "                    # if not found:\n",
    "                    #     #Busca en \"Text\"\n",
    "                    #     for golden_ksa in golden[\"Text\"]:\n",
    "                    #         if golden_ksa == ksa:\n",
    "                    #             index = golden.index[golden[\"Text\"] == golden_ksa].tolist()[0]\n",
    "                    #             _text = golden.at[index, 'Text']\n",
    "                    #             _label = golden.at[index, 'Label']\n",
    "                    #             record = {'occ': occ, 'text': _text, 'label': _label, 'value': 1}\n",
    "                    #             relations_set.add(tuple(record.items()))\n",
    "                    #             relations_df = pd.concat([relations_df, pd.DataFrame([record])], ignore_index=True)\n",
    "                    #             found = True\n",
    "                    #             break\n",
    "\n",
    "\n",
    "                    #Busca en \"Text\"\n",
    "                    if(ksa in setText):\n",
    "                        index = listText.index(ksa)\n",
    "                        _ksa = ksa\n",
    "                        _ksa = golden.at[index, 'Text']\n",
    "                        _ksao = golden.at[index, 'Label']\n",
    "                        #record = {'source': occ, 'target': _ksa, 'ksao': _ksao, 'value': 1, 'origin': 'Text'}\n",
    "                        record = {'occ': occ, 'text': _ksa, 'label': _ksao, 'value': 1}\n",
    "                        relations_set.add(tuple(record.items()))\n",
    "                        relations_df = pd.concat([relations_df, pd.DataFrame([record])], ignore_index=True)\n",
    "                        found = True\n",
    "                    \n",
    "                    if not found:\n",
    "                        #Usar nuestro fine-tuned model para obtener clasificación de KSAO y agregar.\n",
    "                        # Initialize OpenAI client\n",
    "                        client = OpenAI()\n",
    "\n",
    "                        # Call OpenAI's completion API with the current text\n",
    "                        completion = client.chat.completions.create(\n",
    "                            # Usar el modelo finetuned el 4 de Junio de 2024 id: 9WV7nHBF\n",
    "                            model=\"ft:gpt-3.5-turbo-0125:personal::9WV7nHBF\",\n",
    "                            messages=[\n",
    "                                {\"role\": \"system\", \"content\": \"Your job is to identify if the text belongs to knowledge, skill, ability or other based on the KSA taxonomy. Ability is different from skill as it is innate and difficult to measure. You cannot teach ability whereas you can teach skill.\"},\n",
    "                                {\"role\": \"user\", \"content\": ksa}\n",
    "                            ]\n",
    "                        )\n",
    "                        # Get the predicted output\n",
    "                        predicted_output = completion.choices[0].message.content\n",
    "                        \n",
    "                        parts = predicted_output.split(':')\n",
    "                        # If there are two parts and the second part is not empty\n",
    "                        if len(parts) == 2 and parts[1].strip():\n",
    "                            # Capitalize the first letter of the second part and strip any leading/trailing whitespace\n",
    "                            capitalized = parts[1].strip().capitalize()\n",
    "                        else:\n",
    "                            capitalized = predicted_output\n",
    "\n",
    "                        if capitalized in ['Knowledge','Skill','Ability','Other']:\n",
    "                            record = {'occ': occ, 'text': ksa, 'label': capitalized, 'value': 1}\n",
    "                            relations_set.add(tuple(record.items()))\n",
    "                            relations_df = pd.concat([relations_df, pd.DataFrame([record])], ignore_index=True)\n",
    "\n",
    "                            #Add record to golden KSA to prevent further API calls.\n",
    "                            new_row = pd.DataFrame({'Label': [capitalized], 'Text': [ksa]})\n",
    "                            golden_df2 = pd.concat([golden, new_row], ignore_index=True)\n",
    "                            golden_df2.to_csv(dict_file, index=False)\n",
    "                            golden = pd.read_csv(dict_file)\n",
    "\n",
    "    else:\n",
    "        print(f\"{occ_count}.- {occ} - 0\")\n",
    "\n",
    "    occ_count += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Define la función para limpiar y extraer competencias\n",
    "def extract_competences(x):\n",
    "    competences = []\n",
    "    for item in x.split(\"\\n\"):\n",
    "        if \". \" in item:\n",
    "            competence = item.split(\". \")[1].strip()\n",
    "            if competence:\n",
    "                competences.append(competence)\n",
    "        elif \"- \" in item:\n",
    "            competence = item.split(\"- \")[1].strip()\n",
    "            if competence:\n",
    "                competences.append(competence)\n",
    "    return competences\n",
    "\n",
    "# Carga el archivo golden KSA\n",
    "golden = pd.read_csv(\"Golden/dict_ksao_v12-junio-2024.csv\")\n",
    "setText = set(golden[\"Text\"].unique())\n",
    "\n",
    "relations_df = pd.DataFrame(columns=['source', 'target', 'ksao', 'value', 'origin'])\n",
    "\n",
    "file_path = 'indeed_competences/competences_indeed_June_SanFrancisco.csv'\n",
    "if os.path.isfile(file_path) and os.path.getsize(file_path) > 1:\n",
    "    df = pd.read_csv(file_path)\n",
    "    for index, row in df.iterrows():\n",
    "        competences = extract_competences(row['competences_llm'])\n",
    "        found = False\n",
    "        if ksa in setText:\n",
    "            ksa_index = listText.index(ksa)\n",
    "            _ksao = golden.at[ksa_index, 'Label']\n",
    "            record = {'source': row['Occ'], 'target': ksa, 'ksao': _ksao, 'value': 1, 'origin': 'Text'}\n",
    "            relations_set.add(tuple(record.items()))\n",
    "            relations_df = pd.concat([relations_df, pd.DataFrame([record])], ignore_index=True)\n",
    "            found = True\n",
    "        \n",
    "        if not found:\n",
    "            # Usar el modelo finetuned para clasificación\n",
    "            try:\n",
    "                response = client.completions.create(\n",
    "                    model=\"ft:gpt-3.5-turbo-0125:personal::9WV7nHBF\",\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": \"Your job is to identify if the text belongs to knowledge, skill, ability or other based on the KSA taxonomy. Ability is different from skill as it is innate and difficult to measure. You cannot teach ability whereas you can teach skill.\"},\n",
    "                        {\"role\": \"user\", \"content\": ksa}\n",
    "                    ]\n",
    "                )\n",
    "                classification = response.choices[0].text.strip()\n",
    "                \n",
    "                # Capitalize and check validity\n",
    "                if classification.capitalize() in ['Knowledge', 'Skill', 'Ability', 'Other']:\n",
    "                    record = {'source': row['JobTitle'], 'target': ksa, 'ksao': classification.capitalize(), 'value': 1, 'origin': 'Model'}\n",
    "                    relations_set.add(tuple(record.items()))\n",
    "                    relations_df = pd.concat([relations_df, pd.DataFrame([record])], ignore_index=True)\n",
    "                    \n",
    "                    # Update Golden file\n",
    "                    new_row = pd.DataFrame({'Label': [classification.capitalize()], 'Text': [ksa]})\n",
    "                    golden = pd.concat([golden, new_row], ignore_index=True)\n",
    "                    golden.to_csv(dict_file, index=False)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to classify {ksa} due to: {e}\")\n",
    "else:\n",
    "    print(\"File not found or is empty\")\n",
    "\n",
    "# Guardar los resultados en un CSV\n",
    "relations_df.to_csv('output_relations.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = relations_df.groupby(['occ', 'text', 'label', 'value']).size().reset_index(name='count')\n",
    "grouped_df = grouped_df.drop(columns=['value'])\n",
    "grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df.to_csv('tax-infocomm-jsearch-1w-junio-SFCO-2024.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
